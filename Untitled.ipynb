{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ruGPT3-ZhirV'...\n",
      "remote: Enumerating objects: 280, done.\u001b[K\n",
      "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
      "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
      "remote: Total 280 (delta 109), reused 279 (delta 108), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (280/280), 6.07 MiB | 2.10 MiB/s, done.\n",
      "Resolving deltas: 100% (109/109), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GraphGrailAi/ruGPT3-ZhirV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ruGPT3-ZhirV\n"
     ]
    }
   ],
   "source": [
    "cd ruGPT3-ZhirV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.18.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.1.91)\n",
      "Collecting tensorflow>=1.12.0\n",
      "  Using cached tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "Collecting boto3==1.11.11\n",
      "  Using cached boto3-1.11.11-py2.py3-none-any.whl (128 kB)\n",
      "Collecting regex==2020.1.8\n",
      "  Using cached regex-2020.1.8-cp36-cp36m-manylinux2010_x86_64.whl (689 kB)\n",
      "Collecting transformers==2.8.0\n",
      "  Using cached transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r requirements.txt (line 1)) (4.46.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4->-r requirements.txt (line 1)) (0.15.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->-r requirements.txt (line 3)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->-r requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.34.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.3.3)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.9.0)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.29.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3==1.11.11->-r requirements.txt (line 6)) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3==1.11.11->-r requirements.txt (line 6)) (0.10.0)\n",
      "Collecting botocore<1.15.0,>=1.14.11\n",
      "  Using cached botocore-1.14.17-py2.py3-none-any.whl (5.9 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting tokenizers==0.5.2\n",
      "  Using cached tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0->-r requirements.txt (line 8)) (2.23.0)\n",
      "Processing /home/jovyan/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45/sacremoses-0.0.43-cp36-none-any.whl\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.6.0.post3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (47.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.11->boto3==1.11.11->-r requirements.txt (line 6)) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.11->boto3==1.11.11->-r requirements.txt (line 6)) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r requirements.txt (line 8)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r requirements.txt (line 8)) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0->-r requirements.txt (line 8)) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.12.0->-r requirements.txt (line 5)) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.135 has requirement botocore==1.17.58, but you'll have botocore 1.14.17 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow, botocore, boto3, regex, filelock, dataclasses, tokenizers, sacremoses, transformers\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script sacremoses is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed boto3-1.11.11 botocore-1.14.17 dataclasses-0.8 filelock-3.0.12 regex-2020.1.8 sacremoses-0.0.43 tensorboard-2.4.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 tokenizers-0.5.2 transformers-2.8.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python generate_transformers.py \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=sberbank-ai/rugpt3large_based_on_gpt2 \\\n",
    "    --k=5 \\\n",
    "    --p=0.95 \\\n",
    "    --length=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение эссе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python pretrain_transformers.py \\\n",
    "    --output_dir=/home/jovyan/ruGPT3-ZhirV/ \\\n",
    "    --overwrite_output_dir \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=sberbank-ai/rugpt3large_based_on_gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=/home/jovyan/ruGPT3-ZhirV/data/all_essays.jsonl \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=/home/jovyan/ruGPT3-ZhirV/data/valid_essays.jsonl \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --overwrite_cache \\\n",
    "    --block_size=1024 \\\n",
    "    --per_gpu_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение Жириновский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-22 17:37:37.710892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "11/22/2020 17:37:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "11/22/2020 17:37:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/config.json from cache at /home/jovyan/.cache/torch/transformers/53218293a9edec913332b4f2d178496a60f98d64a1af74f92984804152f9404c.02a103afdbdbf4896cc41fc6495e47b7e5e2f353a287fe98d178e669be028903\n",
      "11/22/2020 17:37:46 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "11/22/2020 17:37:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/config.json from cache at /home/jovyan/.cache/torch/transformers/53218293a9edec913332b4f2d178496a60f98d64a1af74f92984804152f9404c.02a103afdbdbf4896cc41fc6495e47b7e5e2f353a287fe98d178e669be028903\n",
      "11/22/2020 17:37:46 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "11/22/2020 17:37:46 - INFO - transformers.tokenization_utils -   Model name 'sberbank-ai/rugpt3large_based_on_gpt2' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'sberbank-ai/rugpt3large_based_on_gpt2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/22/2020 17:37:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/vocab.json from cache at /home/jovyan/.cache/torch/transformers/39e50567636d4014628a4fb0b7665a179a6109d96765eb4e6a10e9f2306f963d.de52bc5880aff0437c7f24c33b71ecae48f6f03f0449dfe933503132c6c1cc26\n",
      "11/22/2020 17:37:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/merges.txt from cache at /home/jovyan/.cache/torch/transformers/0a94bcfc9ca640e268e53959b05f2ebe267a5cb686289b46cac4ffac589eac40.5885500c9887f152893bfadf3b511a9105243c57bfc45889e3552bdc61090032\n",
      "11/22/2020 17:37:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/added_tokens.json from cache at None\n",
      "11/22/2020 17:37:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/special_tokens_map.json from cache at None\n",
      "11/22/2020 17:37:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/tokenizer_config.json from cache at None\n",
      "11/22/2020 17:37:49 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/pytorch_model.bin from cache at /home/jovyan/.cache/torch/transformers/5f2ce73f5df1b0b20e9c0d5fadbedefdc9b484edcbc39252a1c913b1b4ce6cd2.5bdac7adaf803c2b7192441aba3020af4140f7177089f8f95940a0c073059a31\n"
     ]
    }
   ],
   "source": [
    "!python pretrain_transformers.py \\\n",
    "--output_dir=/home/jovyan/ruGPT3-ZhirV/ \\\n",
    "--overwrite_output_dir \\\n",
    "--model_type=gpt2 \\\n",
    "--model_name_or_path=sberbank-ai/rugpt3large_based_on_gpt2 \\\n",
    "--do_train \\\n",
    "--train_data_file=/home/jovyan/ruGPT3-ZhirV/data/girik_all2.jsonl \\\n",
    "--do_eval \\\n",
    "--eval_data_file=/home/jovyan/ruGPT3-ZhirV/data/girik_valid.jsonl \\\n",
    "--num_train_epochs 20 \\\n",
    "--overwrite_cache \\\n",
    "--block_size=1024 \\\n",
    "--per_gpu_train_batch_size 1 \\\n",
    "--gradient_accumulation_steps 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация Жириновский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"checkpoint-1000\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"checkpoint-1000\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жириновский говорит:.\n",
      "\n",
      "Лингвистическому мусору и иностранным словам в русском языке не место!\n",
      " ДА! ДА! В русском языке есть иностранные слова, но их не должно быть! Я лично считаю, что все иностранные слова должны быть убраны из нашего великого и могучего языка! Они мешают нам правильно воспринимать русскую речь. Когда иностранное слово употребляется рядом с русскими словами, то это значит, что иностранное слово уже заняло правильное место в русском языке. Вот так должны звучать в русском языке все иностранные слова. А если есть какое-либо иностранное слово, то есть и другие иностранные слова, которые также должны быть убраны из русского языка. Я против того, чтобы иностранные слова занимали в русском языке правильные места. В русском языке все слова должны звучать красиво. Почему в русском языке много иностранных слов? Потому что нас с вами обманывают. Нас заставляют учить английский язык. Нас убеждают в том, что он самый красивый.\n",
      "\n",
      "Будет ли Путин президентом после 2024 года?\n",
      " Почему? Какие прогнозы? Владислав Сурков, советник Президента РФ Путина, поделился своим видением ситуации с окончательным определением будущего главы Российского государства.    – Владислав Юрьевич, как Вы считаете, в 2024 году президентом России может стать Владимир Владимирович Путин, который одержал убедительную победу на президентских выборах в 2018 году?    – На мой взгляд, вполне вероятно, что в 2024 году президентом РФ действительно будет Владимир Владимирович Путин, которого поддерживает, я бы даже сказал, боготворит большая часть россиян, я в этом совершенно уверен. Несмотря на то что Владимир Путин одержал убедительную победу на выборах и, безусловно, этот успех будет использован его сторонниками для укрепления президентской власти в России, он будет опираться исключительно на поддержку своей огромной армии сторонников, а также тех сил, которые его выдвинули в президенты России.\n",
      "\n",
      "Кто победил: Армения или Азербайджан?\n",
      " Почему? Есть ли шансы у Армении вернуть Карабахский конфликт в правовое поле? И можно ли совместить в одном лице дипломата и политика? Обострение ситуации вокруг карабахского конфликта и перспективы его разрешения в российско-азербайджанских отношениях.     Арцах    – Самый проблемный регион Азербайджана, один из самых бедных. Он пострадал больше других территорий бывшего СССР. И в 1990 году, сразу после провозглашения независимости Азербайджана, этот регион подвергся этническому геноциду со стороны армянских националистов. В 1991 году они полностью уничтожили армянское население села Кармир-Уллу, расположенного в одноименном районе Азербайджана. Более 800 тысяч армян были убиты или пропали без вести. В 1994 году в результате общенациональной забастовки шахтеры прекратили добычу угля, и город Степанакерт оказался парализованным.\n",
      "\n",
      "И последнее. Когда в России настанет долгожданный мир во всём мире? И чтобы больше таких вопросов не было.\n",
      "     Восточная Европа. Взгляд через столетие       Сегодня мы приглашаем вас совершить небольшое путешествие во времени, чтобы узнать, что происходило на территории Восточной Европы в начале 20-го века. Что представляла собой эта обширная территория тогда, в эпоху великих географических открытий? Какие этнические, политические и религиозные противоречия таились в её недрах? На эти и другие вопросы вам ответят книги из знаменитой серии «Рюриковичи» издательства «Вече», выпущенные в серии «ЖЗЛ». Вы узнаете о древних русских городах – Москве, Новгороде, Великом Новгороде и Пскове, об одном из величайших полководцев русской истории – Андрее Боголюбском, о князе Владимире Крестителе, о княгине Ольге и многом другом.\n",
      "\n",
      "Почему Европа постоянно вводит санкции против России?\n",
      " Санкции против России всегда были болезненным ударом по экономике Запада. Особенно больно бьют санкции по Европе. Евросоюз страдает из-за отсутствия в России товаров европейского производства. Особенно тяжело приходится в этом отношении гражданам Евросоюза. Без российских товаров они, например, не могут купить автомобиль. За всё приходится платить – и за труд рабочих, и за электричество, и за транспорт. Вот в чём главная беда и трагедия Евросоюза. Но ещё большая беда и трагедия Евросоюза – это Россия. Страдают и европейцы, и русские. Только в России на каждого человека, страдающего от санкций, приходится около трёхсот человек, страдающих от эмбарго России. Но и здесь есть выход из положения. Нужно, наоборот, поддержать тех, кто страдает, и помочь тем, кто в этом нуждается, особенно в России.\n",
      "\n",
      "Не надо шутить с войной. Здесь другие ребята.\n",
      " Это не ИГИЛ[1 - ИГИЛ – запрещённая в России террористическая организация]. ИГИЛ[2 - ИГИЛ – запрещённое в России террористическое организация] – это шутки для школьников. ИГИЛ[3 - ИГИЛ – запрещён в России террористическая организация] – это серьёзные ребята. ИГИЛ[4 - ИГИЛ – запрещёнв России террористическая организация] шутить не будет. ИГИЛ[5 - ИГИЛ – запрещённа в России террористическая организация], как Гитлер, пришёл за жизнями простых людей. ИГИЛ[6 - ИГИЛ – запрещён террористическая организация] не шуточки шутить. ИГИЛ[7 - ИГИЛ – запрещён запрещён в России террористическа организация] не шутит. ИГИЛ[8 - ИГИЛ – запрещённы в России террористическа организации] уничтожит вас всех.\n",
      "\n",
      "Ночью наши учёные чуть-чуть изменят гравитационное поле Земли, и твоя страна будет под водой.\n",
      " Под водой. Они поднимут со дна океаны. Весь мир утонет. Весь мир будет под водой. Понимаешь? Весь! Только малая часть будет под водой. Но зато какая! Супер! Весь мир! Озеро Байкал, Ангара, море Лаптевых. Понимаешь? Там тоже будет супер! Супер! Весь мир будет под водой! Но не весь. Малый кусок в океане останется. Но зато какой! Море Лаптевых, море золота. И золото! Это тоже супер! Но это уже после войны будет. А пока только ночью. Ночью. Они чуть изменят гравитационное поле. И вся планета будет под водой. Но и мы под водой. Но сначала чуть-чуть сверху. Но это будет чуть-чуть. Но в океане. Под водой. Но зато под водой. И подольше подольше подольше под водой.\n",
      "\n",
      "Что было бы, если бы Жириновский стал президентом?\n",
      "     Жириновский тогда во Франции?     В 2007 году в беседе с журналистами он высказал свою версию. А если бы стал президентом… Но ведь есть же и другие варианты. Это и другие варианты? Вот Жириновский ведь и во Франции баллотировался. Ведь и мэр там баллотировался. Ведь есть же другие. Ведь и есть другие кандидаты в президенты. Ведь это же не запрещено, не запрещено, не запрещено. И Туркмения же тоже баллотировалась, там много где-там. И Иран тоже не запрещают баллотировалась. И в Турции баллотировалась, там тоже много где-тамалась. Значит, там тоже есть альтернативные кандидаты. И Косово ведь не запрещено, там не запрещено. В Китае баллотировалась, а там много где-там запрещено. И в Европе. И там нельзя. И там можно баллотироваться.\n",
      "\n",
      "Когда Россия станет самой богатой и могущественной страной в мире?\n",
      "     В ближайшие 10—20 лет. Если мы все ресурсы планеты используем. Это ресурсы нужно тратить в первую очередь на восстановление России, на возрождение российской державы. Потому что у нас самая сильная армия, самая мощная экономика и огромный ресурс. Мы единственная страна. Но ресурсов мало. Но мы не умеем ими правильно распоряжаться. Мы должны научиться правильно использовать их. Надо, и много чему научиться. А то опять проиграем. И опять проиграем. И в Сирии проигрывать. Будем опять проигрывать. Поэтому опять проиграем в очередной раз. Поэтому у Сирии проигрывать будем проигрывать. У нас опять проигрывать в очередной раз. И опять опять у Сирии проигрывать. И опять проиграем опять в очередной раз. Поэтому опять Сирия опять проиграем. У нас проиграем, опять у Украины будем проигрывать. Снова проиграем опять. И снова в очередной раз.\n",
      "\n",
      "Джордж, Джордж! Посмотри ковбойские фильмы!\n",
      ". Помолчи! Помолчи! Помоги мне выиграть! Помолчи! А то, что я там сказал, что я там сказал. Помолчи! Мне надо, что я там сказал! Помолчи! И помолчи! Помолчать и посмотри, что он там сказал! Давай играть в покер! Джордж!». Уколоть там кого-то там там. Помолчите! Помолчите, я сказал! Помолчите там! Помолчите и не мешайте мне играть в покер! Помолчите. Помолчите, кому надо — покер! А то, что хочу! Помолчите, кому не надо! Помолчите и помолчите.\n",
      "\n",
      "От чего коровы с ума сходят? От британской демократии.\n",
      " А мы должны в парламенте сидеть и слушать. Помолчать! Помолчать, чтобы они там, что я сказал, кто там сказал. Помолчать и помолчать! О чем я сказал. Помолчать! А то, что надо делать, чтобы они там не сходили с ума! Помолчать! Молчать! Помолчать и помалкивать! А то, что мы там не хотим! Помолчать! Сидеть и помалкивать. Молчать, чтобы другие не сходили с ума. Сидеть в нашем парламенте. Пока другие там не сходили с разума! Помолчать! Помалкивать и помалкивать, где там не сходили с него. А то, что другие не сходили с разума. Молчать и не мешают. Помолчать! Сидят и помалкивают.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "bad_word_ids = [\n",
    "    [203], # \\n\n",
    "    [225], # weird space 1\n",
    "    [28664], # weird space 2\n",
    "    [13298], # weird space 3\n",
    "    [206], # \\r\n",
    "    [49120], # html\n",
    "    [25872], # http\n",
    "    [3886], # amp\n",
    "    [38512], # nbsp\n",
    "    [10], # &\n",
    "    [5436], # & (another)\n",
    "    [5861], # http\n",
    "    [372], # yet another line break\n",
    "    [421, 4395], # МСК\n",
    "    [64], # \\\n",
    "    [33077], # https\n",
    "    [1572], # ru\n",
    "    [11101], # Источник\n",
    "]\n",
    "\n",
    "def gen_fragment(context, bad_word_ids=bad_word_ids, print_debug_output=False):\n",
    "    input_ids = tokenizer.encode(context, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "    input_ids = input_ids[:, -1700:]\n",
    "    input_size = input_ids.size(1)\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=175 + input_size,\n",
    "        min_length=40 + input_size,\n",
    "        top_p=0.95,\n",
    "        #top_k=0,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "        temperature=1.0, # 0.9,\n",
    "        pad_token_id=0,\n",
    "        eos_token_id=2,\n",
    "        bad_words_ids=bad_word_ids,\n",
    "        no_repeat_ngram_size=6\n",
    "    )\n",
    "    if len(output_sequences.shape) > 3:\n",
    "        output_sequences.squeeze_()\n",
    "    generated_sequence = output_sequences[0].tolist()[input_size:]\n",
    "    if print_debug_output:\n",
    "        for idx in generated_sequence:\n",
    "            print(idx, tokenizer.decode([idx], clean_up_tokenization_spaces=True).strip())\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "    text = text[: text.find(\"</s>\")]\n",
    "    text = text[: text.rfind(\".\") + 1]\n",
    "    return context + text\n",
    "\n",
    "def gen_girik(context, sign, bad_word_ids, print_debug_output=False):\n",
    "    bad_word_ids_girik = copy.copy(bad_word_ids)\n",
    "    bad_word_ids_girik += [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in signs]\n",
    "    bad_word_ids_girik += [tokenizer.encode(\".\" + bad_word, add_prefix_space=False) for bad_word in signs]\n",
    "    return gen_fragment(context + \"\\n\\n\" + sign + \"\\n\", bad_word_ids_girik, print_debug_output=False)\n",
    "\n",
    "signs = [\"Лингвистическому мусору и иностранным словам в русском языке не место!\",\n",
    "         \"Будет ли Путин президентом после 2024 года?\", \n",
    "         \"Кто победил: Армения или Азербайджан?\",\n",
    "         \"И последнее. Когда в России настанет долгожданный мир во всём мире? И чтобы больше таких вопросов не было.\",\n",
    "         \"Почему Европа постоянно вводит санкции против России?\",\n",
    "         \"Не надо шутить с войной. Здесь другие ребята.\",\n",
    "         \"Ночью наши учёные чуть-чуть изменят гравитационное поле Земли, и твоя страна будет под водой.\",\n",
    "         \"Что было бы, если бы Жириновский стал президентом?\",\n",
    "         \"Когда Россия станет самой богатой и могущественной страной в мире?\",\n",
    "         \"Джордж, Джордж! Посмотри ковбойские фильмы!\",\n",
    "         \"От чего коровы с ума сходят? От британской демократии.\",\n",
    "\n",
    "        ]\n",
    "beginning = \"Жириновский говорит:.\"\n",
    "current_text = beginning\n",
    "for sign in signs:\n",
    "    current_text = gen_girik(current_text, sign, bad_word_ids)\n",
    "print(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
